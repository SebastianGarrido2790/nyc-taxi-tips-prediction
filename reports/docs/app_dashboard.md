# NYC Taxi Tips Predictor: App Architecture & Functionality

## 1. Executive Summary

The `app.py` Streamlit application serves as the interactive frontend (Phase 5) of the NYC Taxi Tip Prediction System. It acts as the bridge between the complex machine learning pipelines (Feature, Training, Inference - FTI) and business stakeholders (like Fleet Managers). The app allows users to visually explore the model's performance, understand what drives tip amounts, and simulate real-time ride predictions without needing any technical expertise.

## 2. Architecture & Data Integration

The application is fully decoupled from the heavy data processing and model training pipelines. Instead of running these tasks on the fly, it relies completely on **pre-computed artifacts** generated by the upstream DVC-orchestrated pipelines.

This design ensures the dashboard loads quickly and remains highly responsive. It utilizes Streamlit's caching mechanisms (`@st.cache_data` and `@st.cache_resource`) to load the following artifacts into memory efficiently:

*   **Model Evaluation Metrics:** Loads `artifacts/model_evaluation/metrics.json` to extract performance markers like Test MAE, MSE, and R¬≤.
*   **Batch Predictions:** Loads `artifacts/predictions/inference_results.csv` to display the outputs of the offline batch inference pipeline.
*   **Champion Model:** Loads the trained `model.joblib` from `artifacts/model_trainer/` to serve real-time interactive predictions.
*   **Training Parameters:** Loads `config/params.yaml` to display the metric weights used during the automated champion selection process.

## 3. Utility Integrations

### Feature Importance Extraction (`src/utils/model_utils.py`)
To ensure the application remains flexible and model-agnostic, the dashboard delegates the extraction of feature importances to a dedicated utility function, `get_feature_importances(model)`, located in `src/utils/model_utils.py`. 

* **Duck Typing Approach:** Rather than relying on strict type checking (e.g., `isinstance(model, RandomForestRegressor)`), this utility inspects the model's attributes (`hasattr`). This prevents hard dependencies on specific libraries (like `scikit-learn` or `xgboost`) and makes the utility resilient to package updates or structural changes.
* **Supported Model Frameworks:**
    * **Tree-based Models:** Extracts arrays directly from `feature_importances_` and `feature_names_in_` if present (e.g., Random Forest, Gradient Boosting).
    * **Linear Models:** If `coef_` is present, it computes the absolute magnitude of the coefficients (`np.abs(model.coef_)`) to rank the relative importance of each feature (e.g., Ridge, Lasso).
    * **XGBoost Models:** Natively checks for `get_booster` and calculates feature importance using the "gain" metric, representing the relative contribution of each feature to the model's splits.

## 4. User Interface & Core Functionality

The dashboard features a persistent sidebar for navigation and is divided into two primary pages. Here is the detailed meaning of each feature these pages have to offer:

### Page 1: Dashboard & Evaluation
This page is dedicated to high-level analytics, model transparency, and offline batch prediction reviews.

*   **Test MAE (Mean Absolute Error):** Represents the average absolute difference between the predicted tip and the actual tip in dollars. A lower value indicates higher precision and reliability in the model's dollar-amount predictions.
*   **Test R¬≤ (Variance Explained):** Indicates the proportion of the variance in the tip amount that is predictable from the trip characteristics. A value closer to 1.0 (or > 0.90) signifies an excellently performing model covering edge cases effectively.
*   **Test MSE (Mean Squared Error):** Represents the average of the squares of the errors. It heavily penalizes larger errors, ensuring the model deals effectively with anomalies and outliers, minimizing extreme deviations.
*   **Champion Selection Weights:** An informative banner displaying the exact metric weights (e.g., MAE, MSE, R2) used by the automated backend pipeline to evaluate, rank, and select this specific champion model from all candidate models.
*   **Feature Importance Chart:** A horizontal bar chart ranking the top 10 factors influencing taxi tips. The scores have been normalized to sum to 100% and rounded to four decimal places, clearly representing the relative percentage of predictive power for each feature. An explanatory caption is included below.
*   **Distribution of Predicted Tips (Histogram):** A visual distribution showing the frequency of different predicted tip amounts across a clearly marked random sample (up to 5,000) of the latest batch inferences. This helps identify common tipping brackets without overwhelming the browser.
*   **Inferences Ledger (Batch Predictions):** A visually enhanced dataframe displaying a random 100-sample subset of recent offline inferences. It neatly maps numeric codes to human-readable text (e.g., mapping Vendor IDs 1 and 2 to "Creative Mobile Technologies, LLC" and "VeriFone Inc."), and formats tips as currency for immediate readability.

### Page 2: Interactive Prediction
This page allows users to simulate taxi rides and query the champion model in real-time, focusing heavily on a frictionless batch-input experience.

*   **Interactive Trip Details (`st.data_editor`):** Instead of static input fields, users manage ride characteristics via an interactive, editable table.
    *   **Batch Prediction Capability:** Users can easily click the `+` icon to append new rows, automatically populated with sensible default values across all columns. 
    *   **Rich Column Configuration:** Every column uses Streamlit's `column_config` to enforce strict minimums, maximums, numeric stepping, and specialized formatting (like currency). Helpful descriptive tooltips (`help`) guide the user on what each input does when they hover over column headers.
    *   **Native Row Deletion:** The table naturally leverages Streamlit's interface to delete trips. Users select specific rows using the built-in left-hand checkboxes and click the native toolbar's trash (`üóëÔ∏è`) icon to efficiently remove those explicit index rows.
*   **On-the-fly Feature Engineering:** When calculating predictions, the app converts the raw temporal inputs (Pickup Hour, Day, Month) into sine and cosine cyclical features. This ensures the model mathematically understands that hour 23 (11 PM) is temporally connected to hour 0 (midnight).
*   **Prediction Alignment & Execution:** The backend dynamically pads any missing contextual columns with zeros, aligning the user's input with the exact structural schema (`feature_names_in_`) the trained model expects, before generating the prediction.
*   **Session State & Reset Functionality:** The table seamlessly preserves the user's edits and strict sequential indices across rerenders using `st.session_state`. A discrete "üîÑ Reset Details" button allows the user to entirely flush the table's state memory and auto-restore the interface to its default single-row state.
*   **Expected Tip Output & Highlighting:** The final dynamically evaluated outcomes are merged into a beautiful display, cleanly stripping away the native dataframe index. The crucial outputs‚Äîthe expected dollar tip amount and relative tip percentage‚Äîare highlighted with Pandas `Styler` utilizing a bold gold background for quick visual isolation. 
*   **Batch Prediction Averages:** Above the final prediction dataframe, analytical `st.metric` cards automatically calculate and visualize the mathematical average of both the expected dollar amount and the percentage tips across the entire processed batch.

## 5. Design & Aesthetics

Following strict guidelines for high-quality, professional tooling, the UI employs **custom CSS** to inject a modern, dark-mode aesthetic. 

*   Uses a tailored `#0E1117` base with `#FAFAFA` text for high contrast.
*   Incorporates subtle accent colors like gold (`#FFD700`) for headers and buttons, alongside green (`#00FF7F`) for positive metrics, bypassing Streamlit's default generic look to deliver a premium user experience.
